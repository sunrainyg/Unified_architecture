<!-- # &#x1F309; Language vison interface -->

&#x1F31F; Official PyTorch implementation of Unified Architectures. 

The master branch works with **PyTorch 1.5+**.

## Overview
We discovered a unified architectures that share similar performance with Transformers

[![pP6cvZT.png](https://s1.ax1x.com/2023/09/09/pP6cvZT.png)](https://imgse.com/i/pP6cvZT)

<details open>
<summary>Major features</summary>


## Links
* [Project Page](https://github.com) 
* [ColabDemo](https://colab.research.google.com/)
* [Paper](https://arxiv.or)


## Citation

If you find our work useful in your research, please cite:

```BiBTeX
@article{,
  title={{}},
  author={},
  journal={},
  year={2023}
}
```
## Set up the environments
Install dependencies by running:
```shell
conda env create -f environment.yaml
conda activate uniarc
```

## Model Zoo


## Get Started
See [Preparing Datasets](DATASET.md).

See [Getting Start](GETTING_STARTED.md) for detailed instructions on training and inference.


## Demo

* Run the demo on Google Colab: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com)



## Acknowledgement

Code is largely based on [Vision Transformer](https://github.com/).

Thank you, for the great open-source project!